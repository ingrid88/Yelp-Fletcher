{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = open(\"political_tweets.csv\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,2016-02-28 23:07:44,Go Bernie!  #FeelTheBern  #SuperTuesday Democracy is not a spectator sport! GET OUT AND VOTE! #Oscars https://t.co/MntIAPCiKl\n",
      "\n",
      "1,2016-02-28 23:07:44,.@freep endorses @HillaryClinton. Calls her the best choice for MI Democrats: https://t.co/6dDZjNSPTt\n",
      "\n",
      "2,2016-02-28 23:07:45,\"State Dept. Releases 1,500 Clinton Emails https://t.co/ZXazBTNDAo #Newsmax via Newsmax_Media\"\n",
      "\n",
      "3,2016-02-28 23:07:45,#ReleaseTheTranscripts so we can see #WhichHillary https://t.co/XdmAKxwZ9C\n",
      "\n",
      "4,2016-02-28 23:07:45,Last year Bernie Sanders told NPR black people couldn't comprehend his policies. Now people of color in  #NV &amp; #SC are less than smart.\n",
      "\n",
      "5,2016-02-28 23:07:45,\"Wonder if Bernie even knows? #ImWithHer The story is about dirty, dirty politics against Hillary #HRC  https://t.co/DFUjuC069I\"\n",
      "\n",
      "6,2016-02-28 23:07:46,Hillary waits to eviscerate Trump with a parade of his victims https://t.co/ayp5OKnZL7 via @DCExaminer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "for line in x:\n",
    "    if i < 10:\n",
    "        print(line)\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = open(\"political_tweets.csv\", 'r')\n",
    "date = []\n",
    "text = []\n",
    "shit = []\n",
    "for line in x:\n",
    "    row = line.split(',')\n",
    "    try:       \n",
    "        text.append(row[2])\n",
    "        date.append(row[1])\n",
    "    except:\n",
    "        shit.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([date,text]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fishery'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize('fishery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from functools import lru_cache\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "lemmatize = lru_cache(maxsize=50000)(wnl.lemmatize)\n",
    "lemmatize('dogs')\n",
    "\n",
    "def lemmas(tweet):\n",
    "    return ' '.join([lemmatize(word) for word in tweet.split(\" \")])\n",
    "\n",
    "\n",
    "def collect(tweet,char):\n",
    "    \"\"\"Input: tweet and Output: hashtags\"\"\"\n",
    "    collection = []\n",
    "    for word in tweet.split(\" \"):\n",
    "        if len(word) > 0 and word[0:len(char)] == char:\n",
    "            collection.append(word[len(char):len(word)].rstrip('\\n'))\n",
    "    return collection\n",
    "\n",
    "collect = lru_cache(maxsize=50000)(collect)\n",
    "\n",
    "\n",
    "def remove_char(tweet,char):\n",
    "    \"\"\"Input: tweet and Output: tweet without specified char\"\"\"\n",
    "    words = [word for word in tweet.split(\" \") if len(word) > 0]\n",
    "    return ' '.join([word for word in words if word[0:len(char)] != char])\n",
    "\n",
    "remove_char = lru_cache(maxsize=50000)(remove_char)\n",
    "\n",
    "def count_chars(tweet,char):\n",
    "    \"\"\"Input: tweet and Output: char count\"\"\"\n",
    "    return len([letter for letter in tweet if letter == char])\n",
    "\n",
    "count_chars = lru_cache(maxsize=50000)(count_chars)\n",
    "\n",
    "def remove_punct(tweet):\n",
    "    \"\"\"Input: tweet and Output: tweet without specified char\"\"\"\n",
    "\n",
    "    exclude = string.punctuation #set([',','.','!',';',\":\",\"?\",\"\"])\n",
    "    return ''.join(ch for ch in tweet if ch not in exclude)\n",
    "\n",
    "remove_punct = lru_cache(maxsize=50000)(remove_punct)\n",
    "\n",
    "def remove_chars(tweet,char_list):\n",
    "    \"\"\"Input: tweet and Output: tweet without specified char\"\"\"\n",
    "    exclude = char_list\n",
    "    return ''.join(ch for ch in tweet if ch not in exclude)\n",
    "\n",
    "\n",
    "def lowercase(tweet):\n",
    "    \"\"\"Input: tweet and Output: tweet without specified char\"\"\"\n",
    "    return tweet.lower()\n",
    "lowercase = lru_cache(maxsize=50000)(lowercase)\n",
    "\n",
    "def remove_numbers(tweet):\n",
    "    return ''.join(ch for ch in tweet if not ch.isdigit())\n",
    "\n",
    "remove_numbers = lru_cache(maxsize=50000)(remove_numbers)\n",
    "# def expand_contractions(tweet):\n",
    "#     \"\"\"Input: tweet and Output: tweet with expanded contractions\"\"\"\n",
    "#     contractions[ch]\n",
    "#     ''.join(ch for ch in tweet if ch not in exclude)\n",
    "# # def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.@freep',\n",
       " 'endorses',\n",
       " '@HillaryClinton.',\n",
       " 'Calls',\n",
       " 'her',\n",
       " 'the',\n",
       " 'best',\n",
       " 'choice',\n",
       " 'for',\n",
       " 'MI',\n",
       " 'Democrats:',\n",
       " 'https://t.co/6dDZjNSPTt\\n']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas(df[1].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    new_tweet = remove_punct(tweet)\n",
    "    new_tweet = remove_chars(new_tweet,['#','@','\\n','&',\"\\\"\"])\n",
    "    new_tweet = remove_char(new_tweet,'https')\n",
    "    new_tweet = lowercase(new_tweet)\n",
    "    new_tweet = remove_numbers(new_tweet)\n",
    "    new_tweet = lemmas(new_tweet)\n",
    "    return new_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' .@freep endorses @HillaryClinton. Calls her the best choice for MI Democrats: https://t.co/dDZjNSPTt\\n '"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we = '12 12'+ df[1].iloc[0]+' 11'\n",
    "remove_numbers(we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "# from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from nltk.corpus import stopwords\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom stoplist\n",
    "STOPLIST = set(stopwords.words('english') + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS))\n",
    "# List of symbols we don't care about\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-----\", \"---\", \"...\", \"“\", \"”\", \"'ve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Every step in a pipeline needs to be a \"transformer\". \n",
    "# Define a custom transformer to clean text using spaCy\n",
    "class CleanTextTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert text to cleaned text\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [cleanText(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    \n",
    "# A custom function to clean the text before sending it into the vectorizer\n",
    "def cleanText(text):\n",
    "    # get rid of newlines\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "# A custom function to tokenize the text using spaCy\n",
    "# and convert to lemmas\n",
    "def tokenizeText(sample):\n",
    "    \n",
    "    # get the tokens using spaCy\n",
    "    tokens = parser(sample)\n",
    "\n",
    "    # lemmatize\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "\n",
    "    # stoplist the tokens\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "\n",
    "    # stoplist symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "\n",
    "    # remove large strings of whitespace\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    while \" \" in tokens:\n",
    "        tokens.remove(\" \")\n",
    "    while \"\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\\n\")\n",
    "\n",
    "    return tokens\n",
    "\n",
    "tokenizeText = lru_cache(maxsize=50000)(tokenizeText)\n",
    "\n",
    "\n",
    "def printNMostInformative(vectorizer, clf, N):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    topClass1 = coefs_with_fns[:N]\n",
    "    topClass2 = coefs_with_fns[:-(N + 1):-1]\n",
    "    print(\"Class 1 best: \")\n",
    "    for feat in topClass1:\n",
    "        print(feat)\n",
    "    print(\"Class 2 best: \")\n",
    "    for feat in topClass2:\n",
    "        print(feat)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['clean'] = df[1].apply(lambda tweet: clean_tweet(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.iloc[1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-02-28 23:07:45</td>\n",
       "      <td>Last year Bernie Sanders told NPR black people...</td>\n",
       "      <td>last year bernie sander told npr black people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-02-28 23:07:45</td>\n",
       "      <td>\"Wonder if Bernie even knows? #ImWithHer The s...</td>\n",
       "      <td>wonder if bernie even know imwithher the story...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-02-28 23:07:46</td>\n",
       "      <td>Hillary waits to eviscerate Trump with a parad...</td>\n",
       "      <td>hillary wait to eviscerate trump with a parade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-02-28 23:07:46</td>\n",
       "      <td>@SusanSarandon @HillaryClinton  Goodnight Hill...</td>\n",
       "      <td>susansarandon hillaryclinton goodnight hillary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-02-28 23:07:47</td>\n",
       "      <td>\"Clinton allies preparing for Trump nomination</td>\n",
       "      <td>clinton ally preparing for trump nomination</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                                                  1  \\\n",
       "5  2016-02-28 23:07:45  Last year Bernie Sanders told NPR black people...   \n",
       "6  2016-02-28 23:07:45  \"Wonder if Bernie even knows? #ImWithHer The s...   \n",
       "7  2016-02-28 23:07:46  Hillary waits to eviscerate Trump with a parad...   \n",
       "8  2016-02-28 23:07:46  @SusanSarandon @HillaryClinton  Goodnight Hill...   \n",
       "9  2016-02-28 23:07:47     \"Clinton allies preparing for Trump nomination   \n",
       "\n",
       "                                               clean  \n",
       "5  last year bernie sander told npr black people ...  \n",
       "6  wonder if bernie even know imwithher the story...  \n",
       "7  hillary wait to eviscerate trump with a parade...  \n",
       "8     susansarandon hillaryclinton goodnight hillary  \n",
       "9        clinton ally preparing for trump nomination  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ats = df[1].apply(lambda tweet: collect(tweet,'@'))\n",
    "hashtag = df[1].apply(lambda tweet: collect(tweet,'#'))\n",
    "urls = df[1].apply(lambda tweet: collect(tweet,'https://'))\n",
    "exclams = df[1].apply(lambda tweet: count_chars(tweet,'!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"ats\"],df[\"hashtag\"],df[\"urls\"],df[\"exclams\"] = ats,hashtag,urls,exclams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frac = df.sample(frac=0.1)\n",
    "\n",
    "documents = list(df.clean)\n",
    "frac_doc = list(frac.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309706"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "      for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "         frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "      for text in texts]\n",
    "\n",
    "from pprint import pprint   # pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.save('/tmp/hillary.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(47892 unique tokens: ['ahead…', 'ferdddaws', 'win/lose', 'oligarchs4hillary', 'bloglovin']...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gensim.corpora.dictionary.Dictionary"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dictionary)\n",
    "type(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame.from_csv(\"political_tweets.csv\")\n",
    "\n",
    "from sklearn.feature_extraction.text import sklearn \n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(list(df[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30971"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frac_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(encoding='utf-8', decode_error='strict', \n",
    "                             strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                             tokenizer=tokenizeText, stop_words=STOPLIST, token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "                             ngram_range=(1, 1), analyzer='word', max_df=1000, min_df=3, \n",
    "                             max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(frac_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--',\n",
       " 'aa',\n",
       " 'aaron',\n",
       " 'aarp',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abc',\n",
       " 'abcnews',\n",
       " 'abcpolitics',\n",
       " 'abedin',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'abolish',\n",
       " 'abortion',\n",
       " 'abowersock',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absurd',\n",
       " 'abt',\n",
       " 'abuse',\n",
       " 'abusive',\n",
       " 'ac',\n",
       " 'aca',\n",
       " 'academy',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptance',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accomplish',\n",
       " 'accomplishment',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accountable',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accuse',\n",
       " 'accuser',\n",
       " 'ace',\n",
       " 'achievement',\n",
       " 'acknowledge',\n",
       " 'aclu',\n",
       " 'act',\n",
       " 'actblue',\n",
       " 'action',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adamsflafan',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'address',\n",
       " 'adele',\n",
       " 'admin',\n",
       " 'administration',\n",
       " 'admire',\n",
       " 'admirer',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'adorable',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'advert',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'adviser',\n",
       " 'advisor',\n",
       " 'advocate',\n",
       " 'af',\n",
       " 'affect',\n",
       " 'affiliation',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afghanistan',\n",
       " 'aflcio',\n",
       " 'afraid',\n",
       " 'african',\n",
       " 'africanamerican',\n",
       " 'africanamericans',\n",
       " 'afternoon',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreement',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahumorlessfem',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'ajenews',\n",
       " 'ajenglish',\n",
       " 'ajkoski',\n",
       " 'ajplus',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alan',\n",
       " 'alangrayson',\n",
       " 'alarm',\n",
       " 'alaska',\n",
       " 'alasscan',\n",
       " 'albamonica',\n",
       " 'alberta',\n",
       " 'album',\n",
       " 'alcindor',\n",
       " 'alert',\n",
       " 'alexander',\n",
       " 'alexburnsnyt',\n",
       " 'alexkatz',\n",
       " 'algeria',\n",
       " 'algiordano',\n",
       " 'alien',\n",
       " 'align',\n",
       " 'alike',\n",
       " 'alisonspalding',\n",
       " 'alive',\n",
       " 'aljazeera',\n",
       " 'allanbrauer',\n",
       " 'allege',\n",
       " 'allen',\n",
       " 'allenclifton',\n",
       " 'alliance',\n",
       " 'allinwithchris',\n",
       " 'allow',\n",
       " 'ally',\n",
       " 'alot',\n",
       " 'alright',\n",
       " 'alternative',\n",
       " 'alternet',\n",
       " 'alum',\n",
       " 'alwaysthinkhow',\n",
       " 'alwaystrump',\n",
       " 'alxandro',\n",
       " 'amandacarpenter',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'ambassador',\n",
       " 'amen',\n",
       " 'amendment',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americatogether',\n",
       " 'amherst',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'ammo',\n",
       " 'amnesia',\n",
       " 'amnesty',\n",
       " 'amodelsmom',\n",
       " 'amok',\n",
       " 'amozu',\n",
       " 'amp',\n",
       " 'ampamp',\n",
       " 'amphillary',\n",
       " 'ampor',\n",
       " 'ampvote',\n",
       " 'amsterdam',\n",
       " 'amy',\n",
       " 'amychozick',\n",
       " 'amyklobuchar',\n",
       " 'amyzworldamy',\n",
       " 'anakasparian',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'anarchy',\n",
       " 'andersoncooper',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'andy',\n",
       " 'and…',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeliname',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'angryblacklady',\n",
       " 'animal',\n",
       " 'anncoulter',\n",
       " 'anniekarni',\n",
       " 'annihilate',\n",
       " 'announce',\n",
       " 'announcement',\n",
       " 'annoy',\n",
       " 'annoying',\n",
       " 'anoint',\n",
       " 'anonijihad',\n",
       " 'anonymous',\n",
       " 'answer',\n",
       " 'anthem',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'antibernie',\n",
       " 'anticipate',\n",
       " 'anticlinton',\n",
       " 'antiestablishment',\n",
       " 'antihillary',\n",
       " 'antisanders',\n",
       " 'antithesis',\n",
       " 'antitrump',\n",
       " 'antonio',\n",
       " 'anxiety',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyones',\n",
       " 'anytime',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apathy',\n",
       " 'apologize',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'applause',\n",
       " 'apple',\n",
       " 'apply',\n",
       " 'appoint',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approve',\n",
       " 'april',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arappeport',\n",
       " 'archive',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'aren’t',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arizona',\n",
       " 'arizonasanders',\n",
       " 'ark',\n",
       " 'arkansas',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'army',\n",
       " 'arrest',\n",
       " 'arrogant',\n",
       " 'art',\n",
       " 'arthur',\n",
       " 'arthuraffect',\n",
       " 'article',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'asap',\n",
       " 'aseitzwald',\n",
       " 'asf',\n",
       " 'ashamed',\n",
       " 'ashbash',\n",
       " 'ashley',\n",
       " 'asian',\n",
       " 'asianamphispanic',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'aspect',\n",
       " 'assad',\n",
       " 'assault',\n",
       " 'assessment',\n",
       " 'asshole',\n",
       " 'assist',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assure',\n",
       " 'atlanta',\n",
       " 'atleast',\n",
       " 'atomic',\n",
       " 'atrocity',\n",
       " 'attack',\n",
       " 'attacker',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attention',\n",
       " 'attn',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attractive',\n",
       " 'at…',\n",
       " 'auburn',\n",
       " 'audience',\n",
       " 'audio',\n",
       " 'austin',\n",
       " 'authentic',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'auto',\n",
       " 'automatically',\n",
       " 'available',\n",
       " 'ave',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'avowed',\n",
       " 'aw',\n",
       " 'awake',\n",
       " 'awaken',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awkward',\n",
       " 'aye',\n",
       " 'a…',\n",
       " 'b',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'bachelor',\n",
       " 'backer',\n",
       " 'backfire',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'backlash',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bae',\n",
       " 'bag',\n",
       " 'baggage',\n",
       " 'baier',\n",
       " 'bait',\n",
       " 'baker',\n",
       " 'bakery',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'ballot',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bandwagon',\n",
       " 'bang',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'banking',\n",
       " 'bankroll',\n",
       " 'bankrupt',\n",
       " 'bankruptcy',\n",
       " 'banksters',\n",
       " 'banner',\n",
       " 'bannerite',\n",
       " 'bar',\n",
       " 'barack',\n",
       " 'barackobama',\n",
       " 'barbara',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'bark',\n",
       " 'barrel',\n",
       " 'barrier',\n",
       " 'barry',\n",
       " 'barton',\n",
       " 'base',\n",
       " 'baseballcrank',\n",
       " 'bash',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basketball',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'batchelorshow',\n",
       " 'bathroom',\n",
       " 'battle',\n",
       " 'bay',\n",
       " 'bbc',\n",
       " 'bbcworld',\n",
       " 'bbsp',\n",
       " 'bc',\n",
       " 'bcrevoltfan',\n",
       " 'bcwilliams',\n",
       " 'beach',\n",
       " 'bear',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beatable',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'beck',\n",
       " 'bed',\n",
       " 'bedford',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behalf',\n",
       " 'behavior',\n",
       " 'beholden',\n",
       " 'belief',\n",
       " 'believable',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'bencooper',\n",
       " 'benefit',\n",
       " 'bengazi',\n",
       " 'benghazi',\n",
       " 'benhowe',\n",
       " 'benjysarlin',\n",
       " 'benreiss',\n",
       " 'bensasse',\n",
       " 'benshapiro',\n",
       " 'benspielberg',\n",
       " 'ber',\n",
       " 'berkeley',\n",
       " 'bern',\n",
       " 'bernard',\n",
       " 'bernardgoldberg',\n",
       " 'berned',\n",
       " 'bernedout',\n",
       " 'berners',\n",
       " 'bernforceone',\n",
       " 'bernieblackout',\n",
       " 'berniebro',\n",
       " 'berniebros',\n",
       " 'berniegreat',\n",
       " 'berniehillary',\n",
       " 'bernieinco',\n",
       " 'berniemedia',\n",
       " 'bernieno',\n",
       " 'bernieorbust',\n",
       " 'bernies',\n",
       " 'berniesandersforpresident',\n",
       " 'berniesandersforpresidents',\n",
       " 'berniesanderss',\n",
       " 'berniesanders…',\n",
       " 'berniesplaining',\n",
       " 'berniesthatman',\n",
       " 'berniestrong',\n",
       " 'bernies…',\n",
       " 'bernieteachers',\n",
       " 'berniethoughts',\n",
       " 'berniewho',\n",
       " 'bernie…',\n",
       " 'bernlennials',\n",
       " 'bernlevshillary',\n",
       " 'bernpress',\n",
       " 'best',\n",
       " 'bestactresshillary',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'betray',\n",
       " 'better',\n",
       " 'beware',\n",
       " 'bff',\n",
       " 'bho',\n",
       " 'bi',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'bible',\n",
       " 'bid',\n",
       " 'bidder',\n",
       " 'biden',\n",
       " 'bidenshairplugs',\n",
       " 'big',\n",
       " 'bigot',\n",
       " 'bigoted',\n",
       " 'bigotry',\n",
       " 'bigpharma',\n",
       " 'bigwig',\n",
       " 'bike',\n",
       " 'billary',\n",
       " 'billclinton',\n",
       " 'billion',\n",
       " 'billionaire',\n",
       " 'billkristol',\n",
       " 'billmaher',\n",
       " 'billpostmus',\n",
       " 'billscher',\n",
       " 'billy',\n",
       " 'bin',\n",
       " 'bind',\n",
       " 'bingo',\n",
       " 'bio',\n",
       " 'bird',\n",
       " 'birmingham',\n",
       " 'birth',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitcoin',\n",
       " 'bitter',\n",
       " 'bizarre',\n",
       " 'bjhare',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blackhistorymonth',\n",
       " 'blacklivesmatter',\n",
       " 'blackout',\n",
       " 'blacktwitter',\n",
       " 'blair',\n",
       " 'blame',\n",
       " 'blanca',\n",
       " 'bland',\n",
       " 'blank',\n",
       " 'blast',\n",
       " 'blatant',\n",
       " 'bless',\n",
       " 'blind',\n",
       " 'blindly',\n",
       " 'blisstabitha',\n",
       " 'blitzkrieg',\n",
       " 'blk',\n",
       " 'blm',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blood',\n",
       " 'bloodbath',\n",
       " 'bloomberg',\n",
       " 'blow',\n",
       " 'blowout',\n",
       " 'blue',\n",
       " 'bluenationrev',\n",
       " 'bluff',\n",
       " 'bluffton',\n",
       " 'blumenthal',\n",
       " 'blupfront',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bobblehead',\n",
       " 'bobbytbd',\n",
       " 'bobdolan',\n",
       " 'body',\n",
       " 'boggle',\n",
       " 'bogus',\n",
       " 'boi',\n",
       " 'boil',\n",
       " 'bokoharam',\n",
       " 'bold',\n",
       " 'bolster',\n",
       " 'bomb',\n",
       " 'bombard',\n",
       " 'bombshell',\n",
       " 'bond',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'booker',\n",
       " 'bookert',\n",
       " 'boom',\n",
       " 'boomer',\n",
       " 'boost',\n",
       " 'boot',\n",
       " 'border',\n",
       " 'bore',\n",
       " 'boring',\n",
       " 'bos',\n",
       " 'bospoli',\n",
       " 'boston',\n",
       " 'bostondotcom',\n",
       " 'bostonglobe',\n",
       " 'bostonherald',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bounce',\n",
       " 'bout',\n",
       " 'bow',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boycott',\n",
       " 'bpolitics',\n",
       " 'bra',\n",
       " 'brace',\n",
       " 'brag',\n",
       " 'brain',\n",
       " 'brainsbern',\n",
       " 'brainwash',\n",
       " 'brand',\n",
       " 'brave',\n",
       " 'bravo',\n",
       " 'bre',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breakingnews',\n",
       " 'breaktheinternet',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breeawnuhh',\n",
       " 'breitbart',\n",
       " 'breitbartnews',\n",
       " 'bret',\n",
       " 'bretbaier',\n",
       " 'brian',\n",
       " 'brianefallon',\n",
       " 'brianstelter',\n",
       " 'bribe',\n",
       " 'brick',\n",
       " 'bridge',\n",
       " 'brie',\n",
       " 'brief',\n",
       " 'briefly',\n",
       " 'bright',\n",
       " 'brikeilarcnn',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'brit',\n",
       " 'brithume',\n",
       " 'britney',\n",
       " 'bro',\n",
       " 'broad',\n",
       " 'broadcast',\n",
       " 'broaddrick',\n",
       " 'broadly',\n",
       " 'brock',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'broker',\n",
       " 'brokered',\n",
       " 'brooklyn',\n",
       " 'bros',\n",
       " 'brother',\n",
       " 'brotherhood',\n",
       " 'brown',\n",
       " 'brucebartlett',\n",
       " 'bruh',\n",
       " 'brutal',\n",
       " 'bt',\n",
       " 'btw',\n",
       " 'btwn',\n",
       " 'bubba',\n",
       " 'bubble',\n",
       " 'buck',\n",
       " 'bucksexton',\n",
       " 'bud',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buffalo',\n",
       " 'buffet',\n",
       " 'buffett',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'building',\n",
       " 'bull',\n",
       " 'bullshit',\n",
       " 'bully',\n",
       " 'bum',\n",
       " 'bump',\n",
       " 'bumper',\n",
       " 'bunch',\n",
       " 'burdentruth',\n",
       " 'burkina',\n",
       " 'burlington',\n",
       " 'burn',\n",
       " 'burnie',\n",
       " 'bury',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'busis',\n",
       " 'bust',\n",
       " 'busy',\n",
       " 'butt',\n",
       " 'butterfingerdr',\n",
       " 'button',\n",
       " 'but…',\n",
       " 'buy',\n",
       " 'buzz',\n",
       " 'buzzfeed',\n",
       " 'buzzfeedandrew',\n",
       " 'buzzfeednews',\n",
       " 'bvgamble',\n",
       " 'bye',\n",
       " 'byebernie',\n",
       " 'bypass',\n",
       " 'byrd',\n",
       " 'byronyork',\n",
       " 'by…',\n",
       " 'c',\n",
       " 'cable',\n",
       " 'cablefixer',\n",
       " 'cablegate',\n",
       " 'cakewalk',\n",
       " 'california',\n",
       " 'called',\n",
       " 'caller',\n",
       " 'camera',\n",
       " 'camerota',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'campaigntrump',\n",
       " 'campus',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candidacy',\n",
       " 'candidate',\n",
       " 'canidate',\n",
       " 'cannabis',\n",
       " 'canvass',\n",
       " 'can’t',\n",
       " 'capacity',\n",
       " 'capehartj',\n",
       " 'capital',\n",
       " 'capitalism',\n",
       " 'capitalist',\n",
       " 'capitol',\n",
       " 'captain',\n",
       " 'capuano',\n",
       " 'car',\n",
       " 'carbon',\n",
       " 'card',\n",
       " 'care',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'carl',\n",
       " 'carly',\n",
       " 'carminezozzora',\n",
       " 'carnage',\n",
       " 'carolina',\n",
       " 'carolinian',\n",
       " 'carpetbagger',\n",
       " 'carry',\n",
       " 'carson',\n",
       " 'cartel',\n",
       " 'carter',\n",
       " 'cartoon',\n",
       " 'cascamike',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cassandrarules',\n",
       " 'cast',\n",
       " 'castro',\n",
       " 'cat',\n",
       " 'catastrophic',\n",
       " 'catch',\n",
       " 'catcher',\n",
       " 'catholic',\n",
       " 'catspaws',\n",
       " 'caucus',\n",
       " 'cause',\n",
       " 'cbs',\n",
       " 'cbseveningnews',\n",
       " 'cbsnews',\n",
       " 'cc',\n",
       " 'ccot',\n",
       " 'cd',\n",
       " 'ceasers',\n",
       " 'ceiling',\n",
       " 'celebrate',\n",
       " 'celebration',\n",
       " 'celebrity',\n",
       " 'cell',\n",
       " 'cenk',\n",
       " 'cenkuygur',\n",
       " 'censor',\n",
       " 'censorednewsnow',\n",
       " 'censorship',\n",
       " 'center',\n",
       " 'central',\n",
       " 'centre',\n",
       " 'centrist',\n",
       " 'century',\n",
       " 'ceo',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'cfr',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'chairman',\n",
       " 'chairmnoomowmow',\n",
       " 'chairwoman',\n",
       " 'challenge',\n",
       " 'champion',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'channel',\n",
       " 'chant',\n",
       " 'chaos',\n",
       " 'chaos’……hillary',\n",
       " 'chappaquas',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charity',\n",
       " 'charles',\n",
       " 'charlescwcooke',\n",
       " 'charlesmblow',\n",
       " 'charlie',\n",
       " 'charliesheen',\n",
       " 'charm',\n",
       " 'chart',\n",
       " 'chase',\n",
       " 'chastises',\n",
       " 'chat',\n",
       " 'chatter',\n",
       " 'cheap',\n",
       " 'cheat',\n",
       " 'cheating',\n",
       " 'check',\n",
       " 'cheer',\n",
       " 'chef',\n",
       " 'chelsea',\n",
       " 'chelseaclinton',\n",
       " 'chemical',\n",
       " 'cheney',\n",
       " 'cherokeenative',\n",
       " 'cheryl',\n",
       " 'chicago',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childrens',\n",
       " 'chile',\n",
       " 'chill',\n",
       " 'chillin',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'chitchat',\n",
       " 'choice',\n",
       " 'chomsky',\n",
       " 'choose',\n",
       " 'choosecruz',\n",
       " 'chop',\n",
       " 'chozick',\n",
       " 'chris',\n",
       " 'chrislhayes',\n",
       " 'chrismegerian',\n",
       " 'chrisrock',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christichat',\n",
       " 'christie',\n",
       " 'christinaaamh',\n",
       " 'christine',\n",
       " 'chronicle',\n",
       " 'chuck',\n",
       " 'chucknellis',\n",
       " 'chucktodd',\n",
       " 'chuckw',\n",
       " 'church',\n",
       " 'cia',\n",
       " 'cindycallinsky',\n",
       " 'circumstance',\n",
       " 'circus',\n",
       " 'cite',\n",
       " 'citizen',\n",
       " 'citizensfedup',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'ckhyppolite',\n",
       " 'claim',\n",
       " 'clan',\n",
       " 'clarify',\n",
       " 'class',\n",
       " 'classification',\n",
       " 'classified',\n",
       " 'classify',\n",
       " 'classroom',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearance',\n",
       " 'clearly',\n",
       " 'cleveland',\n",
       " 'clever',\n",
       " 'cli',\n",
       " 'click',\n",
       " 'clickgt',\n",
       " 'cliff',\n",
       " 'climate',\n",
       " 'climatechange',\n",
       " 'climb',\n",
       " 'clint',\n",
       " 'clintonamp',\n",
       " 'clintonamps',\n",
       " 'clintonbush',\n",
       " 'clintonemails',\n",
       " 'clintonfoundation',\n",
       " 'clintonsanders',\n",
       " 'clintonshateobama',\n",
       " 'clintontrump',\n",
       " 'clinton–as',\n",
       " 'clinton…',\n",
       " 'clip',\n",
       " 'clipper',\n",
       " 'clipster',\n",
       " 'clique',\n",
       " 'clmtboston',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closely',\n",
       " 'closer',\n",
       " 'closet',\n",
       " 'cloud',\n",
       " 'clout',\n",
       " 'clown',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'clueless',\n",
       " 'clyburn',\n",
       " 'cmclymer',\n",
       " 'cmcneilstein',\n",
       " 'cmon',\n",
       " 'cnbc',\n",
       " 'cnn',\n",
       " 'cnnbrk',\n",
       " 'cnnorc',\n",
       " 'cnnpolitics',\n",
       " 'cnns',\n",
       " 'cnnsitroom',\n",
       " 'cnntonight',\n",
       " 'cnn—call',\n",
       " 'cnrapp',\n",
       " 'cnservativegal',\n",
       " 'coach',\n",
       " 'coalition',\n",
       " 'coast',\n",
       " 'coat',\n",
       " 'coattail',\n",
       " 'cocaucus',\n",
       " 'coconspirator',\n",
       " 'coddle',\n",
       " 'code',\n",
       " 'codger',\n",
       " 'coffee',\n",
       " 'coffin',\n",
       " 'cohn',\n",
       " 'coin',\n",
       " 'col',\n",
       " 'cold',\n",
       " 'colin',\n",
       " 'collapse',\n",
       " 'collect',\n",
       " 'collection',\n",
       " 'collective',\n",
       " 'college',\n",
       " 'collegesbernie',\n",
       " 'collins',\n",
       " 'colombia',\n",
       " 'colombian',\n",
       " 'colonel',\n",
       " 'color',\n",
       " 'colorado',\n",
       " 'coloradoan',\n",
       " 'coloradobernie',\n",
       " 'columbia',\n",
       " 'columbian',\n",
       " 'column',\n",
       " 'com',\n",
       " 'combat',\n",
       " 'combine',\n",
       " 'come',\n",
       " 'comedy',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comic',\n",
       " 'command',\n",
       " 'commander',\n",
       " 'commanderinchief',\n",
       " 'comment',\n",
       " 'commentary',\n",
       " 'commercial',\n",
       " 'commie',\n",
       " 'commission',\n",
       " 'commit',\n",
       " 'committee',\n",
       " 'common',\n",
       " 'commondreams',\n",
       " 'communism',\n",
       " 'communist',\n",
       " 'community',\n",
       " 'communityscene',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'comparison',\n",
       " 'compass',\n",
       " 'compassion',\n",
       " ...]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from functools import lru_cache\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "lemmatize = lru_cache(maxsize=50000)(wnl.lemmatize)\n",
    "lemmatize('dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "lemmatize = lru_cache(maxsize=50000)(wnl.lemmatize)\n",
    "lemmatize('dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol NOUN lol\n",
      "that ADJ that\n",
      "is VERB be\n",
      "rly ADV rly\n",
      "funny ADJ funny\n",
      ":) PUNCT :)\n",
      "This DET this\n",
      "is VERB be\n",
      "gr8 VERB gr8\n",
      "i NOUN i\n",
      "rate VERB rate\n",
      "it NOUN it\n",
      "8/8 NUM 8/8\n",
      "! PUNCT !\n",
      "! PUNCT !\n",
      "! PUNCT !\n"
     ]
    }
   ],
   "source": [
    "messyData = \"lol that is rly funny :) This is gr8 i rate it 8/8!!!\"\n",
    "parsedData = parser(messyData)\n",
    "for token in parsedData:\n",
    "    print(token.orth_, token.pos_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "y = np.array([1, 1, 1, 2, 2, 2])\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X, y)\n",
    "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
    "              solver='svd', store_covariance=False, tol=0.0001)\n",
    "print(clf.predict([[-0.8, -1]]))\n",
    "[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
